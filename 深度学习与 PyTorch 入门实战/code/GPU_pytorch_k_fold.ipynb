{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU pytorch k-fold.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrEE861HWrrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lesson 32 Tain-Val-Test 划分"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBoetJlKXBut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import torch \n",
        " import torch.nn as nn \n",
        " import torch.nn.functional as F\n",
        " import torch.optim as optim \n",
        " from torchvision import datasets, transforms "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u11ql8Dxe8zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size= 100 \n",
        "learning_rate = 0.001 \n",
        "epochs = 500 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLLI3zEDfCUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_db = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_db,\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_db = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]))\n",
        "test_loader = torch.utils.data.DataLoader(test_db,\n",
        "    batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8_LZzT1faq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('train: ', len(train_db))\n",
        "print('test: ', len(test_db))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obeG7GXVfoIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_db, val_db = torch.utils.data.random_split(train_db,[50000,10000])\n",
        "\n",
        "print('train: ', len(train_db))\n",
        "print('validation: ', len(val_db))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZA8bRYFgK91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_db, batch_size = batch_size, shuffle = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_db, batch_size= batch_size, shuffle = True\n",
        ")\n",
        "\n",
        "print('train: ', len(train_db))\n",
        "print('validation: ', len(val_db))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYH5czSngm8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# module \n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784,200),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Linear(200,200),\n",
        "            nn.LeakyReLU(inplace =True),\n",
        "            nn.Linear(200,10),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inaLjaXJilhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h_PeEWBh6gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use GPU \n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "net = MLP().to(device)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr= learning_rate)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27AhxVbaiSaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for index, (data, target) in enumerate(train_loader):\n",
        "        data = data.view(-1,28*28)\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        logits = net(data)\n",
        "\n",
        "        loss = criterion(logits, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if index %10 ==0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, index * len(data), len(train_loader.dataset),\n",
        "                       100. * index / len(train_loader), loss.item()))\n",
        "            \n",
        "\n",
        "    test_loss =0 \n",
        "    correct =0 \n",
        "\n",
        "    for data, target in val_loader:\n",
        "        data = data.view(-1, 28*28)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        logits = net(data)\n",
        "        test_loss += criterion(logits, target).item()\n",
        "\n",
        "        pred = logits.max(dim=1)[1]\n",
        "\n",
        "        correct += pred.eq(target.data).sum()\n",
        "\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print('\\nVAL set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6AnlvAAuhS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}